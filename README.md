# 6.5840
Learning for MIT 6.5840
Lab1
本项目主要做的是复现简单的MapReduce任务，熟悉流程。

首先是test目录下，测试了一下简单的rpc功能，相当于是将任务封装成函数，申请一个监听端口，然后客户端向服务器端发出请求，使用rpc功能，远程服务调用，传入要调用的函数名称以及相应的参数，如此，服务器端在收到请求之后，会响应建立链接并处理该请求。
而上述使用rpc的过程，真正执行任务的是服务器端，也就是说我们的客户端只是一个请求资源，传递任务，等待执行结果的过程。
而在MapReduce中，我们又不尽相同。MapReduce相当于是有一个集中的Master节点负责分配调度各种资源，这个资源也就是各个不同的服务器，而这些服务器是要来分担负载的，所以应当是Master使用rpc向所有建立好链接的服务器请求其去执行MapReduce任务。

回到Lab1任务中，我们要编写mr目录下三个文件以实现本项目，对应rpc、coordinator、worker三个文件的执行关系为：
1、coordinator 维护任务队列，并等待来自 worker 的任务请求。/或者coordinator主动向worker发起请求。

2、当一个 worker 请求任务时，coordinator 会将任务分配给该 worker。

3、worker 接收任务并执行它。

4、worker 完成任务后，将结果返回给 coordinator。

5、coordinator 收集并处理来自多个 worker 的结果，可能会进行进一步的决策，例如任务重新分配或通知客户端任务完成。

这个过程可以在整个分布式系统中重复执行，以处理大量的任务。

由于本身提供的代码框架里是默认在一台服务器上运行的，所以给出的是对于输入文件的路径信息，真正的读取操作是在远程调用的时候，而非是Master节点读取，然后分发给每个节点的。实际上，对于大文件如果采用这种处理方式，相当于是Master节点还有一次对于文件流的读取解析，传输，占用很大的网络带宽。所以一般而言我们的分布式系统会有多个存储中心，对于大文件而言，数据被分散切片到不同的存储服务器上，Master节点的分布式调度RPC调用会将每个分片分给不同的worker，而后worker节点到对应的存储节点进行数据的读取使用，（或者是存储节点和运算节点是放在一起的，这样调度的话给该节点分配的任务就是对于他能本地直接读取的内容的计算任务）。

